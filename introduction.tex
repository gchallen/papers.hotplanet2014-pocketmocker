% 25 Mar 2014 : GWA : Goal is 1 page including bullet contributions at end
% and paper structure paragraph.

\section{Introduction and Motivation}
\label{sec-introduction}

Recent studies show that privacy is one of today's smartphone users' top
concerns with their devices, second only to battery
life~\cite{truste-privacy}. A plurality of 43\% of users are \textit{not}
willing to share any information about themselves with a company in exchange
for a free or subsidized app, despite ad-driven free apps being common on
mobile app marketplaces. And as smartphone apps get smarter they will be able
to determine more about our lives through passive observation. Mapping
services already know where we are, sensors reveal whether we walked or
drove, social networking apps track our relationship with the person we came
to meet, and payment apps reveal what we did together. And as analytical
approaches that fuse data from multiple sensors improve, smartphones will
likely reveal even deeper facts about us: the strength of our friendships,
our devotion to our job, even our level of happiness.

% With the digital portraits painted by smartphones becoming ever clearer, we
% believe it is time to give users more control over their smartphone-derived
% digital identities. Many other components of our digital lives already
% provide ways to curate the information we provide in order to mold our
% digital personas. Users of dating sites post pictures that they hope others
% will find attractive, users of photo-sharing sites post more photos of
% themselves out performing interesting activities than of mundane sedentary
% ones, and users of social networking sites carefully choose the movies and
% music they list in their profiles to create a particular desired
% impression. While using these online services requires surrendering some
% amount of privacy, the active participation they require provides users
% with some control over what information they reveal and the impression they
% create. In contrast, the passive data collection that smartphones
% facilitate represents a dangerous simultaneous loss of \textit{both}
% privacy and control.

% 25 Mar 2014 : GWA : TODO : Look at Android Ap Ops
% http://www.google.com/search?q=android+selective+permissions. Do similar
% mechanisms exist on other platforms? Try to bring this paragraph up to
% date...

Today's smartphone platforms have attempted to address this loss of privacy
through permission mechanisms that limit apps' access to user information.
Unfortunately, this approach has many well-documented problems: apps request
permissions they don't need~\cite{taintdroid-osdi,demystified-ccs11}, and
users do not understand the implications of permissions that apps
request~\cite{androidperms-soups12}. The ``take-it-or-leave-it'' model used
by Android provides no options for users uncomfortable with the permissions
an app requests other than not to install it. Even a more selective
``take-it-or-break-it'' approach~\cite{apex-asiaccs10} that could allow users
selectively to enable individual permissions is no cure.  Users are still
forced to make poorly informed tradeoffs between privacy and functionality,
as it is unclear how an app might behave if denied access to information or
fed random values. As a result, users tend to give apps the permissions they
request.

% 25 Mar 2014 : GWA : TODO : Look at the flow permissions paper for some
% citation inspiration here.

One fundamental problem with all permission-based approaches to protecting
privacy on smartphones is that many apps legitimately require access to
certain kinds of sensitive information to function properly. When I am lost,
my mapping app must know where I am in order to route me to my destination.
When I am monitoring my fitness, my pedometer must be able to access the
accelerometer to count the number of steps I take each day. It is
unreasonable to expect users to be able to distinguish between legitimate and
illegitimate information requests, and burdensome and error-prone to ask them
to enable data sources only when they feel comfortable with what a particular
app is doing.

Obviously users can always choose not to use apps with which they feel
uncomfortable, and there are many projects looking at how to make safer app
marketplaces by preventing malicious apps that \textit{only} want to steal
personal information. However, this focus on malicious apps obscures a harder
truth: even legitimate data collected by non-malicious apps represents a
privacy risk. For a typical user who wants to read email, browse the web,
take pictures, and use social networking and messaging clients, legitimate
data collection by legitimate apps still constitutes a significant privacy
risk. Even after preventing unnecessary data collection by legitimate apps, a
tradeoff between privacy and usability remains. The only options remaining
are to remove useful apps or stop using the smartphone entirely---both
unattractive.

Rather than trying to limit or control the flow of accurate user data,
another approach is to overwhelm the accurate data with inaccurate data. If
the inaccurate data is random, this has the effect of obscuring the accurate
data. For example, if an app is using location updates to try and determine a
users work schedule, inserting random locations would make that more
difficult. However, the inaccurate data can also be designed to achieve a
specific objective. We call this process \textit{mocking} and the data used
\textit{mocked} data. Continuing with the same example, mocking the app would
mean injecting data that would cause the app to reach an incorrect conclusion
rather than no conclusion.

Mocking differs fundamentally from privacy. While privacy aims to limit
access to data under the assumption that less data reveals less about users,
understanding privacy implications still requires smartphone users to answer
difficult questions. If I install and use this app, what will it be able to
determine about me? How much of the data that this app is collecting is
really necessary? What are the privacy implications of even the legitimate
data that this app is collecting? Accurate answers to these questions remain
elusive at best. There are billions of dollars at stake for companies in
determining how to do more accurate mobile data analytics, and few if any
have a business interest in divulging either how their algorithms work or
what they know about us. While new tools help smartphone users determine
\textit{how much} data smartphone apps collect and even where that data goes,
\textit{what it reveals} remains uncertain. In contrast mocking reduces the
power of legitimate data by injecting enough mocked data to achieve
user-defined objectives and has the potential to change ``I don't know what
this app knows about me'' uncertainty into ``I know what this data will cause
this app to conclude'' certainty. And unlike privacy, which requires hiding
data and thus potentially impacting apps' functionality, mocking ensures that
apps continue to function normally during each mocking session, making it
simpler for users to understand and use.

In this paper we explore the desirability and implications of widespread app
mocking. We begin by presenting mocking scenarios in the next section to help
make our discussion more concrete and further illustrate the differences
between mocking and privacy. Section~\ref{sec-feasibility} continues with a
brief discussion of the feasibility of this approach, noting that for Android
devices mocking can be performed either with our without modifications to the
underlying smartphone platform software. In Section~\ref{sec-survey} we
present survey results indicating that users are aware of and concerned by
smartphone data collection and willing to utilize mocking techniques.
Section~\ref{sec-discussion} continues by raising some of the ethical issues
raised by mocking, after which Section~\ref{sec-conclusion} concludes the
paper.
